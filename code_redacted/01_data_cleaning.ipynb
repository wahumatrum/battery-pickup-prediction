{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import missingno as msno\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data from `battery.csv` into a pandas data frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"../data/battery_with_geo.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head() # redacted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape # redacted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns # redacted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data info and show the data type of each column\n",
    "print(df.info()) # redacted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum() # redacted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique() # redacted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(df) # redacted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we see a pattern:\n",
    "- **IF** disponiert_am is missing **THEN** also abholdatum is missing\n",
    "- both columns have *almost* the same missing values\n",
    "  - *in some few cases* abholdatum has a missing value where disponiert_am has a value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "long                           0.029636\n",
       "lat                            0.029636\n",
       "transporteur                   0.000000\n",
       "volle_Addresse                 0.000000\n",
       "angeforderter_behältertyp      0.000000\n",
       "angemeldete_containeranzahl    0.000000\n",
       "nettogewicht_in_kg             0.000000\n",
       "bruttogewicht_in_kg            0.000000\n",
       "zurückgemeldet_am              0.000000\n",
       "abholjahr                      0.000000\n",
       "abholdatum                     0.000000\n",
       "auftrag_bestätigt_am           0.000000\n",
       "auftragsdatum                  0.000000\n",
       "auftragsstatus                 0.000000\n",
       "auftragstyp                    0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nice one liner for statistical overview over missing values\n",
    "df.isna().mean().mul(100).sort_values(ascending=False).iloc[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing constant values for the missing values\n",
    "We do this only for non-date columns. date columns are handled in \"Data Types and Transforming Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#impute \"unknown\" for  string columns\n",
    "df[[\"name_2\", \"stasse\", \"name_1\",]] = df[[\"name_2\", \"stasse\", \"name_1\",]].fillna(\"unknown\")\n",
    "\n",
    "#impute \"other\" for categorical columns\n",
    "df[[\"typ\", \"gelieferter_behältertyp\"]] = df[[\"typ\", \"gelieferter_behältertyp\"]].fillna(\"other\")\n",
    "\n",
    "#impute 0 for numeric columns\n",
    "df[[\"kreisgemeindeschlüssel\", \"länderschlüssel\", \"region\"]] = df[[\"kreisgemeindeschlüssel\", \"länderschlüssel\", \"region\"]].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with dublicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how many duplicated rows exist in the data frame\n",
    "df.duplicated().value_counts() # redacted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicates\n",
    "df = df.drop_duplicates()\n",
    "# reset index inplace\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "df.head(5) # redacted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check again for missing values\n",
    "df.isna().sum() # redacted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the total number of missing values\n",
    "print(df.isnull().values.sum()) # redacted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.name_2.value_counts())\n",
    "print(\"count of missing values in name_2: \", df.name_2.isna().sum()) # redacted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Übersicht über gelieferte Behältertypen\n",
    "print(df.gelieferter_behältertyp.value_counts())\n",
    "print(\"count of missing values in gelieferter_behältertyp: \", df.gelieferter_behältertyp.isna().sum()) # redacted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gelieferter_behältertyp'].isnull() # redacted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see Pandas recognized the \"0s\" as a missing value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Types and Transforming Data\n",
    "\n",
    "In the following we want to get the data types into the right shape. The dtype `object` for ecample means that there are several data types in the corresponding column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data types in data frame\n",
    "df.dtypes # redacted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numeric columns\n",
    "df.select_dtypes('number') # redacted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.astype({'kreisgemeindeschlüssel': int})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['nettogewicht_in_kg'] = df['nettogewicht_in_kg'].apply(lambda x: x.replace(',','.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.astype({'nettogewicht_in_kg': float})\n",
    "df['nettogewicht_in_kg'] = df['nettogewicht_in_kg'].apply(lambda x: round(x))\n",
    "df = df.astype({'nettogewicht_in_kg': int})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# type of first date entry\n",
    "type(df['auftragsdatum'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# type of first date entry\n",
    "type(df['auftrag_bestätigt_am'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see our date entry is just a string. We can change that to a date time very easy as we already learned. Note that you also could do that in the beginning, when you read in the csv file with the parameter `parse_date=['date']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change \"date\" dtype to datetime with format %Y/%m/%d\n",
    "df['auftragsdatum'] = pd.to_datetime(df['auftragsdatum'], format='%d.%m.%y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas._libs.tslibs.timestamps.Timestamp"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# type of first date entry\n",
    "type(df['auftragsdatum'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auftragsdatum</th>\n",
       "      <th>auftrag_bestätigt_am</th>\n",
       "      <th>disponiert_am</th>\n",
       "      <th>abholdatum</th>\n",
       "      <th>zurückgemeldet_am</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>-</td>\n",
       "      <td>06.01.20</td>\n",
       "      <td>20.01.20</td>\n",
       "      <td>21.01.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>-</td>\n",
       "      <td>21.01.20</td>\n",
       "      <td>09.01.20</td>\n",
       "      <td>22.01.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>-</td>\n",
       "      <td>08.01.20</td>\n",
       "      <td>13.01.20</td>\n",
       "      <td>13.01.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  auftragsdatum auftrag_bestätigt_am disponiert_am abholdatum  \\\n",
       "0    2020-01-06                    -           NaN        NaN   \n",
       "1    2020-01-06                    -      06.01.20   20.01.20   \n",
       "2    2020-01-06                    -      21.01.20   09.01.20   \n",
       "3    2020-01-06                    -           NaN        NaN   \n",
       "4    2020-01-06                    -      08.01.20   13.01.20   \n",
       "\n",
       "  zurückgemeldet_am  \n",
       "0               NaN  \n",
       "1          21.01.20  \n",
       "2          22.01.20  \n",
       "3               NaN  \n",
       "4          13.01.20  "
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_datum = pd.DataFrame(df[['auftragsdatum', 'auftrag_bestätigt_am', 'disponiert_am', 'abholdatum', 'zurückgemeldet_am']])\n",
    "df_datum.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['auftrag_bestätigt_am'] = df['auftrag_bestätigt_am'].replace('-', np.nan)\n",
    "df['auftrag_bestätigt_am'] = df['auftrag_bestätigt_am'].fillna(\"01.01.99\")\n",
    "\n",
    "df['auftrag_bestätigt_am'] = pd.to_datetime(df['auftrag_bestätigt_am'], format='%d.%m.%y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['disponiert_am'] = df['disponiert_am'].fillna(\"01.01.99\")\n",
    "\n",
    "df['disponiert_am'] = pd.to_datetime(df['disponiert_am'], format='%d.%m.%y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['abholdatum'] = df['abholdatum'].fillna(\"01.01.99\")\n",
    "\n",
    "df['abholdatum'] = pd.to_datetime(df['abholdatum'], format='%d.%m.%y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['zurückgemeldet_am'] = df['zurückgemeldet_am'].fillna(\"01.01.99\")\n",
    "\n",
    "df['zurückgemeldet_am'] = pd.to_datetime(df['zurückgemeldet_am'], format='%d.%m.%y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auftragsdatum</th>\n",
       "      <th>auftrag_bestätigt_am</th>\n",
       "      <th>disponiert_am</th>\n",
       "      <th>abholdatum</th>\n",
       "      <th>zurückgemeldet_am</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>1999-01-01</td>\n",
       "      <td>1999-01-01</td>\n",
       "      <td>1999-01-01</td>\n",
       "      <td>1999-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>1999-01-01</td>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>2020-01-20</td>\n",
       "      <td>2020-01-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>1999-01-01</td>\n",
       "      <td>2020-01-21</td>\n",
       "      <td>2020-01-09</td>\n",
       "      <td>2020-01-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>1999-01-01</td>\n",
       "      <td>1999-01-01</td>\n",
       "      <td>1999-01-01</td>\n",
       "      <td>1999-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>1999-01-01</td>\n",
       "      <td>2020-01-08</td>\n",
       "      <td>2020-01-13</td>\n",
       "      <td>2020-01-13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  auftragsdatum auftrag_bestätigt_am disponiert_am abholdatum  \\\n",
       "0    2020-01-06           1999-01-01    1999-01-01 1999-01-01   \n",
       "1    2020-01-06           1999-01-01    2020-01-06 2020-01-20   \n",
       "2    2020-01-06           1999-01-01    2020-01-21 2020-01-09   \n",
       "3    2020-01-06           1999-01-01    1999-01-01 1999-01-01   \n",
       "4    2020-01-06           1999-01-01    2020-01-08 2020-01-13   \n",
       "\n",
       "  zurückgemeldet_am  \n",
       "0        1999-01-01  \n",
       "1        2020-01-21  \n",
       "2        2020-01-22  \n",
       "3        1999-01-01  \n",
       "4        2020-01-13  "
      ]
     },
     "execution_count": 492,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_datum = pd.DataFrame(df[['auftragsdatum', 'auftrag_bestätigt_am', 'disponiert_am', 'abholdatum', 'zurückgemeldet_am']])\n",
    "df_datum.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['auftrag_bestätigt_am']).size() # redacted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(df['herkömliche_übergabestelle'].isnull().values.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df['herkömliche_übergabestelle'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bool"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace string by boolean\n",
    "df['herkömliche_übergabestelle'] = df['herkömliche_übergabestelle'].map({'x':True}) \n",
    "type(df['herkömliche_übergabestelle'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['herkömliche_übergabestelle'].fillna(True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(df['herkömliche_übergabestelle'].isnull().values.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace string by boolean\n",
    "df['qualifizierte_annahmestelle'] = df['qualifizierte_annahmestelle'].map({'x':True, '-': False}) \n",
    "df['qualifizierte_annahmestelle'] # redacted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace string by boolean\n",
    "df['qualifizierte_sammelstelle'] = df['qualifizierte_sammelstelle'].map({'x':True, '-': False}) \n",
    "df['qualifizierte_sammelstelle'] # redacted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The count of distinct categories in angeforderter_behältertyp is:  20\n",
      "The count of distinct categories in gelieferter_behältertyp is:  18\n"
     ]
    }
   ],
   "source": [
    "# display number of distinct elements\n",
    "print(\"The count of distinct categories in angeforderter_behältertyp is: \", df.angeforderter_behältertyp.nunique())\n",
    "print(\"The count of distinct categories in gelieferter_behältertyp is: \", df.gelieferter_behältertyp.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics for column age_group\n",
    "print(df.angeforderter_behältertyp.value_counts())\n",
    "# redacted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.gelieferter_behältertyp.value_counts())\n",
    "# redacted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.region.value_counts() # redacted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,\n",
       "       13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25.,\n",
       "       26., 27., 28., 29., 30., 31., 32., 33., 34., 35., 36., 37.])"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_regions = df.region.unique()\n",
    "sorted_regions.sort()\n",
    "sorted_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns\n",
    "df.drop('los_1p7', axis='columns', inplace=True)\n",
    "df.drop('auftragsjahr', axis='columns', inplace=True)\n",
    "df.drop('auftragsmonat', axis='columns', inplace=True)\n",
    "df.drop('länderschlüssel', axis='columns', inplace=True)\n",
    "df.drop('region', axis='columns', inplace=True)\n",
    "df.drop('disponiert_am', axis='columns', inplace=True)\n",
    "df.drop('kategorie', axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data types in data frame\n",
    "df.dtypes # redacted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with Outliers\n",
    "In the following we want to detect and handle outliers. \n",
    "\n",
    "An outlier is an exceptionally high or low value. Based on this definition, a first idea to detect outliers would be to simply cut down the highest and lowest points of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a better understanding, lets look only the numerical values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select numeric columns\n",
    "df_numeric = pd.DataFrame(df[['bruttogewicht_in_kg', 'nettogewicht_in_kg', 'angemeldete_containeranzahl', 'angeforderter_behältertyp']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bruttogewicht_in_kg</th>\n",
       "      <th>nettogewicht_in_kg</th>\n",
       "      <th>angemeldete_containeranzahl</th>\n",
       "      <th>angeforderter_behältertyp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Fass (60 Ltr.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>431</td>\n",
       "      <td>415</td>\n",
       "      <td>15</td>\n",
       "      <td>Kiste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>306</td>\n",
       "      <td>297</td>\n",
       "      <td>3</td>\n",
       "      <td>Fass (60 Ltr.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>Kiste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>194</td>\n",
       "      <td>8</td>\n",
       "      <td>Kiste</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bruttogewicht_in_kg  nettogewicht_in_kg  angemeldete_containeranzahl  \\\n",
       "0                    0                   0                            1   \n",
       "1                  431                 415                           15   \n",
       "2                  306                 297                            3   \n",
       "3                    0                   0                            8   \n",
       "4                  200                 194                            8   \n",
       "\n",
       "  angeforderter_behältertyp  \n",
       "0            Fass (60 Ltr.)  \n",
       "1                     Kiste  \n",
       "2            Fass (60 Ltr.)  \n",
       "3                     Kiste  \n",
       "4                     Kiste  "
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_numeric.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numeric.describe().T # redacted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we can observe from reading this data:\n",
    "- `bruttogewicht_in_kg`: very high (# redacted) 'bruttogewicht' \n",
    "- `nettogewicht_in_kg`: we can see few outliers that 1) have negative weight and 2) very high 'nettogewicht' (# redacted)\n",
    "- `angemeldete_containeranzahl`: very high 'contraineranzahl' (# redacted) (outlier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping the outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with \"brutto_gewicht_in_kg\" larger than 30000\n",
    "df = df.drop(df[df.bruttogewicht_in_kg > 30000].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with \"nettogewicht_in_kg\" larger than 25000\n",
    "df = df.drop(df[df.nettogewicht_in_kg > 25000].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all rows with negative \"nettogewicht_in_kg\" \n",
    "df = df.drop(df[df.nettogewicht_in_kg < 0.0].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the rest non-relevant values\n",
    "#df = df.drop(df[(df.bruttogewicht_in_kg > 15000) & (df.angemeldete_containeranzahl == 10)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with \"angemeldete_containeranzahl\" larger than 300\n",
    "df = df.drop(df[df.angemeldete_containeranzahl > 300].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with \"angemeldete_containeranzahl\" = 0\n",
    "df = df.drop(df[df.angemeldete_containeranzahl == 0].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with \"auftragsstatus\" = 'Storniert'\n",
    "df = df.drop(df[df.auftragsstatus == 'Storniert'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with \"auftragsstatus\" = 'Fehlfahrt'\n",
    "df = df.drop(df[df.auftragsstatus == 'Fehlfahrt'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df[df.nettogewicht_in_kg == 1].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df[df.bruttogewicht_in_kg == 3].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query(\"bruttogewicht_in_kg == nettogewicht_in_kg\") # redacted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.bundesland.value_counts() # redacted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.bundesland = np.where(((df.plz == 27639) & (df.bundesland == '?')), 'Niedersachsen', df.bundesland)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.bundesland = np.where(((df.plz == 57234) & (df.bundesland == '?')), 'Nordrhein-Westfalen', df.bundesland)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.bundesland = np.where(((df.plz == 33333) & (df.bundesland == '?')), 'Nordrhein-Westfalen', df.bundesland)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape raw data: \", raw_df.shape)\n",
    "print(\"Shape cleaned outliers in the numerical values: \", df.shape)\n",
    "print(\"Shape cleaned data without missing values and outliers in weights: \", df.shape)\n",
    "# redacted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show min and max netto and brutto of the cleaned data, respectively\n",
    "print(\"min netto: \", df.nettogewicht_in_kg.min())\n",
    "print(\"max netto: \", df.nettogewicht_in_kg.max())\n",
    "print()\n",
    "print(\"min brutto: \", df.bruttogewicht_in_kg.min())\n",
    "print(\"max brutto: \", df.bruttogewicht_in_kg.max())\n",
    "# redacted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "# redacted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum() # redacted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.volle_Addresse.isna()] # redacted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 addresses are not complete so there's also not lat, long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle will preserve the full state of a pandas dataframe including dtypes\n",
    "df.to_pickle(\"../data/battery_cleaned_with_geo.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8 (main, Dec 12 2022, 11:24:53) \n[Clang 14.0.0 (clang-1400.0.29.202)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f9b1f7ee9b8716eae474e4e403dd4dff0f662765920b174d1bb68198c0d2acd4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
